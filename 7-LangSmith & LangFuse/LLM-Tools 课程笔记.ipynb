{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ee8ce2-4b03-4b57-b85d-b4fb6db26570",
   "metadata": {},
   "source": [
    "# ğŸ’¡ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbc193-f8fc-4e18-85e7-45d3e8a6383a",
   "metadata": {},
   "source": [
    "1. ç³»ç»Ÿæ€§ç»´æŠ¤ã€æµ‹è¯•ã€ç›‘æ§ä¸€ä¸ª LLM åº”ç”¨\n",
    "2. å­¦ä¹ ä½¿ç”¨ä¸»æµçš„å·¥å…·å®Œæˆä¸Šè¿°å·¥ä½œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2fb93-5991-48e1-898b-a48ebfda9481",
   "metadata": {},
   "source": [
    "## ç»´æŠ¤ä¸€ä¸ªç”Ÿäº§çº§çš„ LLM åº”ç”¨ï¼Œæˆ‘ä»¬éœ€è¦åšä»€ä¹ˆï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb536c0-3997-457a-b360-62fbbc910454",
   "metadata": {},
   "source": [
    "1. å„ç§æŒ‡æ ‡ç›‘æ§ä¸ç»Ÿè®¡ï¼šè®¿é—®è®°å½•ã€å“åº”æ—¶é•¿ã€Tokenç”¨é‡ã€è®¡è´¹ç­‰ç­‰\n",
    "2. è°ƒè¯• Prompt\n",
    "3. æµ‹è¯•/éªŒè¯ç³»ç»Ÿçš„ç›¸å…³è¯„ä¼°æŒ‡æ ‡\n",
    "4. æ•°æ®é›†ç®¡ç†ï¼ˆä¾¿äºå›å½’æµ‹è¯•ï¼‰\n",
    "5. Prompt ç‰ˆæœ¬ç®¡ç†ï¼ˆä¾¿äºå‡çº§/å›æ»šï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579d2ef-95ed-4e05-a025-940434a88100",
   "metadata": {},
   "source": [
    "## é’ˆå¯¹ä»¥ä¸Šéœ€æ±‚ï¼Œæˆ‘ä»¬ä»‹ç»ä¸‰ä¸ªç”Ÿäº§çº§ LLM App ç»´æŠ¤å¹³å°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb8637-fd33-438c-bfba-5acc62ff8500",
   "metadata": {},
   "source": [
    "1. é‡ç‚¹è®²è§£ **LangFuse**: å¼€æº + SaaSï¼ŒLangSmith å¹³æ›¿ï¼Œå¯é›†æˆ LangChain ä¹Ÿå¯ç›´æ¥å¯¹æ¥ OpenAI APIï¼›\n",
    "2. ç®€å•è®²è§£ **LangSmith**: LangChain çš„å®˜æ–¹å¹³å°ï¼ŒSaaS æœåŠ¡ï¼Œéå¼€æº\n",
    "3. ç®€å•è®²è§£ **Prompt Flow**ï¼šå¾®è½¯å¼€å‘ï¼Œå¼€æº + Azure AIäº‘æœåŠ¡ï¼Œå¯é›†æˆ Semantic Kernelï¼ˆä½†è²Œåˆç¥ç¦»ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4068b0-b4bc-42a3-864e-47e019130832",
   "metadata": {},
   "source": [
    "## 1ã€LangFuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a821ce-8be3-40d2-bb30-7ae9f0e0c7a8",
   "metadata": {},
   "source": [
    "å¼€æºï¼Œæ”¯æŒ LangChain é›†æˆæˆ–åŸç”Ÿ OpenAI API é›†æˆ\n",
    "\n",
    "å®˜æ–¹ç½‘ç«™ï¼šhttps://langfuse.com/\n",
    "\n",
    "é¡¹ç›®åœ°å€ï¼šhttps://github.com/langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c22be-791e-4c1d-858f-4202a4a51786",
   "metadata": {},
   "source": [
    "1. é€šè¿‡å®˜æ–¹äº‘æœåŠ¡ä½¿ç”¨ï¼šæ³¨å†Œ: cloud.langfuse.comï¼Œåˆ›å»º API Keyï¼Œå¹¶æ·»åŠ å¦‚ä¸‹é…ç½®\n",
    "```sh\n",
    "LANGFUSE_SECRET_KEY=\"sk-lf-...\"\n",
    "LANGFUSE_PUBLIC_KEY=\"pk-lf-...\"\n",
    "# å®˜æ–¹æœåŠ¡å™¨\n",
    "LANGFUSE_HOST=\"https://us.cloud.langfuse.com\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ccf21-e6d5-4269-9930-e936b3d081e1",
   "metadata": {},
   "source": [
    "2. é€šè¿‡ Docker æœ¬åœ°éƒ¨ç½²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a84beb-14f1-466c-bd29-c1dc4d1b9e40",
   "metadata": {},
   "source": [
    "```sh\n",
    "# Clone repository\n",
    "git clone https://github.com/langfuse/langfuse.git\n",
    "cd langfuse\n",
    " \n",
    "# Run server and db\n",
    "docker compose up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75383b1-fa32-4456-8c58-9ebdd6cf841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0349c3-75e6-406f-aa45-7477d1557fc3",
   "metadata": {},
   "source": [
    "### 1.1 é€šè¿‡ LangChain çš„å›è°ƒé›†æˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c47782b-9b28-4490-907a-0aa54f0b3e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# å®šä¹‰å›è°ƒå¤„ç†å™¨\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦å¯ç”¨ï¼Œè¿”å›Trueå³å¯ç”¨\n",
    "langfuse_handler.auth_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee41e249-1151-440b-bba0-334cd024b9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, AGIClass! Excited to engage with you! How can I assist you today?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"Say hello to {input}!\") \n",
    "])\n",
    "\n",
    "\n",
    "# å®šä¹‰è¾“å‡ºè§£æå™¨\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# å®šä¹‰Chain\n",
    "chain = (\n",
    "    {\"input\":RunnablePassthrough()} \n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke(input=\"AGIClass\", config={\"callbacks\":[langfuse_handler]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b67f7a-6c4b-4c90-86fa-2f052e732087",
   "metadata": {},
   "source": [
    "### 1.2ã€Trace\n",
    "- ä¸€ä¸ªTraceç›¸å½“äºä¸€è½®å¯¹è¯\n",
    "- ç”¨ Trace å¯ä»¥è®°å½•ä¸€ä¸ªå¤šæ¬¡è°ƒç”¨ LLM çš„è¿‡ç¨‹\n",
    "\n",
    "\n",
    " ä»¥ä¸‹é¢åº”ç”¨ä¸ºä¾‹ï¼š\n",
    "\n",
    "**AGIè¯¾å ‚è·Ÿè¯¾åŠ©æ‰‹**ï¼Œæ ¹æ®è¯¾ç¨‹å†…å®¹ï¼Œåˆ¤æ–­å­¦ç”Ÿé—®é¢˜æ˜¯å¦éœ€è¦è€å¸ˆè§£ç­”\n",
    "\n",
    "1. åˆ¤æ–­è¯¥é—®é¢˜æ˜¯å¦éœ€è¦è€å¸ˆè§£ç­”ï¼Œå›å¤'Y'æˆ–'N'\n",
    "2. åˆ¤æ–­è¯¥é—®é¢˜æ˜¯å¦å·²æœ‰åŒå­¦é—®è¿‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e216f6d0-88cb-4bdb-bc1d-3bd932b7d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»º PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "need_answer_prompt=PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "ä½ æ˜¯AIGCè¯¾ç¨‹çš„åŠ©æ•™ï¼Œä½ çš„å·¥ä½œæ˜¯ä»å­¦å‘˜çš„è¯¾å ‚äº¤æµä¸­é€‰æ‹©å‡ºéœ€è¦è€å¸ˆå›ç­”çš„é—®é¢˜ï¼ŒåŠ ä»¥æ•´ç†ä»¥äº¤ç»™è€å¸ˆå›ç­”ã€‚\n",
    " \n",
    "è¯¾ç¨‹å†…å®¹:\n",
    "{outlines}\n",
    "*********\n",
    "å­¦å‘˜è¾“å…¥:\n",
    "{user_input}\n",
    "*********\n",
    "å¦‚æœè¿™æ˜¯ä¸€ä¸ªéœ€è¦è€å¸ˆç­”ç–‘çš„é—®é¢˜ï¼Œå›å¤Yï¼Œå¦åˆ™å›å¤Nã€‚\n",
    "åªå›å¤Yæˆ–Nï¼Œä¸è¦å›å¤å…¶ä»–å†…å®¹ã€‚\"\"\")\n",
    "\n",
    "check_duplicated_prompt=PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "å·²æœ‰æé—®åˆ—è¡¨:\n",
    "[\n",
    "{question_list}\n",
    "]\n",
    "*********\n",
    "æ–°æé—®:\n",
    "{user_input}\n",
    "*********\n",
    "å·²æœ‰æé—®åˆ—è¡¨æ˜¯å¦æœ‰å’Œæ–°æé—®ç±»ä¼¼çš„é—®é¢˜? å›å¤Yæˆ–N, Yè¡¨ç¤ºæœ‰ï¼ŒNè¡¨ç¤ºæ²¡æœ‰ã€‚\n",
    "åªå›å¤Yæˆ–Nï¼Œä¸è¦å›å¤å…¶ä»–å†…å®¹ã€‚\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ac9d67-725c-43bc-a08b-cb2e187bd060",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlines=\"\"\"\n",
    "LangChain\n",
    "æ¨¡å‹ I/O å°è£…\n",
    "æ¨¡å‹çš„å°è£…\n",
    "æ¨¡å‹çš„è¾“å…¥è¾“å‡º\n",
    "PromptTemplate\n",
    "OutputParser\n",
    "æ•°æ®è¿æ¥å°è£…\n",
    "æ–‡æ¡£åŠ è½½å™¨ï¼šDocument Loaders\n",
    "æ–‡æ¡£å¤„ç†å™¨\n",
    "å†…ç½®RAGï¼šRetrievalQA\n",
    "è®°å¿†å°è£…ï¼šMemory\n",
    "é“¾æ¶æ„ï¼šChain/LCEL\n",
    "å¤§æ¨¡å‹æ—¶ä»£çš„è½¯ä»¶æ¶æ„ï¼šAgent\n",
    "ReAct\n",
    "SelfAskWithSearch\n",
    "Assistants API\n",
    "LangServe\n",
    "LangChain.js\n",
    "\"\"\"\n",
    "\n",
    "question_list=[\n",
    "    \"è°¢è°¢è€å¸ˆ\",\n",
    "    \"LangChainå¼€æºå—\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15cc8923-701f-4fe9-91e8-68a2cf723880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»º chain\n",
    "model = ChatOpenAI(temperature=0)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain1 = (\n",
    "    need_answer_prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain2 = (\n",
    "    check_duplicated_prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0de918b2-9e99-479d-8035-f838972ee152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langfuse.client import Langfuse\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªæ–°trace\n",
    "def create_trace(user_id):\n",
    "    langfuse = Langfuse()\n",
    "    trace_id = str(uuid.uuid4())\n",
    "    trace = langfuse.trace(name=\"assistant\", id=trace_id, user_id=user_id)\n",
    "    return trace\n",
    "\n",
    "# ä¸»æµç¨‹\n",
    "def verify_question(question: str, outlines: str, question_list: list, user_id: str) -> bool:\n",
    "    trace = create_trace(user_id)\n",
    "    handler = trace.get_langchain_handler()\n",
    "    # åˆ¤æ–­æ˜¯å¦éœ€è¦å›ç­”\n",
    "    if chain1.invoke({\"user_input\":question,\"outlines\": outlines},config={\"callbacks\":[handler]}) == 'Y':\n",
    "        # åˆ¤æ–­æ˜¯å¦ä¸ºé‡å¤é—®é¢˜\n",
    "        if chain2.invoke({\"user_input\":question,\"question_list\": \"\\n\".join(question_list)},config={\"callbacks\":[handler]}) == 'N':\n",
    "            question_list.append(question)\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5ff6685-2a26-467b-9a2a-0497833d9162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# å®é™…è°ƒç”¨\n",
    "ret = verify_question(\n",
    "    \"LangChainæ”¯æŒJavaå—\",\n",
    "    outlines,\n",
    "    question_list,\n",
    "    user_id=\"fxy\",\n",
    ")\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d524756",
   "metadata": {},
   "source": [
    "<img src=\"langfuse1.png\" width=\"1000px\">\n",
    "\n",
    "<img src=\"trace-detail.png\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb2e27-4c18-424c-99dd-b3c02c29dfcb",
   "metadata": {},
   "source": [
    "### 1.3ã€Session\n",
    "\n",
    "- ç”¨ Session è®°å½•ä¸€ä¸ªç”¨æˆ·çš„å¤šè½®å¯¹è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0c37548-2b93-404e-b4c3-e65d7e9ac019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: ä½ å¥½\n",
      "AI: ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "User: ä½ å¯ä»¥å¹²ä»€ä¹ˆï¼Ÿ\n",
      "AI: æˆ‘å¯ä»¥å¸®åŠ©ä½ è§£ç­”é—®é¢˜ã€æä¾›å­¦ä¹ èµ„æºã€è§£é‡Šè¯¾ç¨‹å†…å®¹ã€ååŠ©ä½œä¸šæˆ–é¡¹ç›®ï¼Œä»¥åŠæä¾›ä¸€èˆ¬æ€§çš„å­¦ä¹ å»ºè®®ã€‚å¦‚æœä½ æœ‰å…·ä½“çš„éœ€æ±‚æˆ–é—®é¢˜ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼\n",
      "User: \n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import (AIMessage, HumanMessage, SystemMessage)\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"ä½ æ˜¯AGIClassçš„è¯¾ç¨‹åŠ©ç†ã€‚\"), \n",
    "]\n",
    "\n",
    "handler = CallbackHandler(user_id=\"fxy\", trace_name=\"session_test\",session_id=str(uuid.uuid4()))\n",
    "\n",
    "while True:\n",
    "    user_input=input(\"User: \")\n",
    "    if user_input.strip() == \"\":\n",
    "        break\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    response = llm.invoke(messages,config={\"callbacks\":[handler]})\n",
    "    print(\"AI: \"+response.content)\n",
    "    messages.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f42090e",
   "metadata": {},
   "source": [
    "<img src=\"session.png\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c529d3b7-91f2-41fa-a090-04f4746e72d0",
   "metadata": {},
   "source": [
    "### 1.4ã€æ•°æ®é›†ä¸æµ‹è¯•\n",
    "\n",
    "- åˆ©ç”¨ç”¨æˆ·èŠå¤©æ•°æ®é›†å’Œå›å½’æµ‹è¯•åŠŸèƒ½ä¸æ–­ä¼˜åŒ–æˆ‘ä»¬çš„å¤§æ¨¡å‹ä»£ç \n",
    "- [Langfuse Datasets Cookbook](https://langfuse.com/docs/datasets/python-cookbook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4507fd3-616e-45be-9d0f-49ae347019b7",
   "metadata": {},
   "source": [
    "### 1.4.1ã€åœ¨çº¿æ ‡æ³¨\n",
    "\n",
    "1. åˆ›å»ºä¸€ä¸ªæ•°æ®é›†\n",
    "\n",
    "<img src=\"create_dataset.png\" width=\"1000px\">\n",
    "\n",
    "2. å°†ä¸€æ¡TraceåŠ å…¥æ•°æ®é›†\n",
    "\n",
    "<img src=\"add_to_dataset.png\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe4c35-fba3-49d9-ae9e-9d2bdffb7b0b",
   "metadata": {},
   "source": [
    "### 1.4.2ã€ä¸Šä¼ å·²æœ‰æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef67abc0-09d9-4548-92e8-158ed23f77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "qa_pairs = []\n",
    "with open('example_dataset.jsonl','r',encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        example = json.loads(line.strip())\n",
    "        qa_pairs.append(example)\n",
    "\n",
    "\n",
    "from langfuse import Langfuse\n",
    "from langfuse.model import CreateDatasetRequest, CreateDatasetItemRequest\n",
    " \n",
    "# init\n",
    "langfuse = Langfuse()\n",
    "\n",
    "langfuse.create_dataset(name=\"wiki_qa\")\n",
    "\n",
    "for item in qa_pairs[:20]:\n",
    "  langfuse.create_dataset_item(\n",
    "        dataset_name=\"wiki_qa\",\n",
    "        input=item[\"question\"],\n",
    "        expected_output=item[\"answer\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff22810",
   "metadata": {},
   "source": [
    "<img src=\"lf_upload_data.png\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b9e3b-0684-4273-b2af-2919c077b059",
   "metadata": {},
   "source": [
    "### 1.4.3ã€å®šä¹‰è¯„ä¼°å‡½æ•°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc85360b-ab9a-4fac-919b-c84b691e760c",
   "metadata": {},
   "source": [
    "å¦‚ä½•æ¯”è¾ƒä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼æ€§ï¼šä¸€äº›ç»å…¸ NLP çš„è¯„æµ‹æ–¹æ³•ï¼ˆé€‰ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ea3a5-e750-4a21-a092-a7d1cadf1a21",
   "metadata": {},
   "source": [
    "1. **ç¼–è¾‘è·ç¦»**ï¼šä¹Ÿå«è±æ–‡æ–¯å¦è·ç¦»(Levenshtein),æ˜¯é’ˆå¯¹äºŒä¸ªå­—ç¬¦ä¸²çš„å·®å¼‚ç¨‹åº¦çš„é‡åŒ–é‡æµ‹ï¼Œé‡æµ‹æ–¹å¼æ˜¯çœ‹è‡³å°‘éœ€è¦å¤šå°‘æ¬¡çš„å¤„ç†æ‰èƒ½å°†ä¸€ä¸ªå­—ç¬¦ä¸²å˜æˆå¦ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚\n",
    "   - å…·ä½“è®¡ç®—è¿‡ç¨‹æ˜¯ä¸€ä¸ªåŠ¨æ€è§„åˆ’ç®—æ³•ï¼šhttps://zhuanlan.zhihu.com/p/164599274\n",
    "   - è¡¡é‡ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼åº¦æ—¶ï¼Œå¯ä»¥ä»¥è¯ä¸ºå•ä½è®¡ç®—\n",
    "2. **BLEU Score**:\n",
    "   - å®ƒé€šè¿‡æ¯”è¾ƒæœºå™¨ç”Ÿæˆçš„æ–‡æœ¬ä¸ä¸€ä¸ªæˆ–å¤šä¸ªå‚è€ƒæ–‡æœ¬ï¼Œè¡¡é‡ç”Ÿæˆæ–‡æœ¬ä¸å‚è€ƒæ–‡æœ¬åœ¨**è¯æ±‡**å±‚é¢ä¸Šçš„ç›¸ä¼¼æ€§ã€‚BLEUä»…åŸºäºè¯æ±‡é‡åˆåº¦è¿›è¡Œè¯„ä¼°ï¼Œä¸è€ƒè™‘æ–‡æœ¬çš„è¯­ä¹‰ï¼Œå› æ­¤å³ä½¿ç”Ÿæˆæ–‡æœ¬åœ¨æ„ä¹‰ä¸Šæ˜¯æ­£ç¡®çš„ï¼Œä½†å¦‚æœåœ¨è¯æ±‡é€‰æ‹©ä¸Šä¸åŒï¼Œåˆ†æ•°å¯èƒ½ä»ç„¶è¾ƒä½ã€‚\n",
    "   - è®¡ç®—è¾“å‡ºä¸å‚ç…§å¥ä¹‹é—´çš„ n-gram å‡†ç¡®ç‡ï¼ˆn=1...4ï¼‰\n",
    "   - å¯¹çŸ­è¾“å‡ºåšæƒ©ç½š\n",
    "   - åœ¨æ•´ä¸ªæµ‹è¯•é›†ä¸Šå¹³å‡ä¸‹è¿°å€¼\n",
    "   - å®Œæ•´è®¡ç®—å…¬å¼ï¼š$\\mathrm{BLEU}_4=\\min\\left(1,\\frac{output-length}{reference-length}\\right)\\left(\\prod_{i=1}^4 precision_i\\right)^{\\frac{1}{4}}$\n",
    "   - å‡½æ•°åº“ï¼šhttps://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "3. **Rouge Score**:\n",
    "   - Rouge-Nï¼šå°†æ¨¡å‹ç”Ÿæˆçš„ç»“æœå’Œæ ‡å‡†ç»“æœæŒ‰ N-gram æ‹†åˆ†åï¼Œåªè®¡ç®—å¬å›ç‡ï¼›\n",
    "   - Rouge-L: åˆ©ç”¨äº†æœ€é•¿å…¬å…±å­åºåˆ—ï¼ˆLongest Common Sequenceï¼‰ï¼Œè®¡ç®—ï¼š$P=\\frac{LCS(c,r)}{len(c)}$, $R=\\frac{LCS(c,r)}{len(r)}$, $F=\\frac{(1+\\beta^2)PR}{R+\\beta^2P}$\n",
    "   - å‡½æ•°åº“ï¼šhttps://pypi.org/project/rouge-score/\n",
    "   - å¯¹æ¯” BLEU ä¸ ROUGEï¼š\n",
    "     - BLEU èƒ½è¯„ä¼°æµç•…åº¦ï¼Œä½†æŒ‡æ ‡åå‘äºè¾ƒçŸ­çš„ç¿»è¯‘ç»“æœï¼ˆbrevity penalty æ²¡æœ‰æƒ³è±¡ä¸­é‚£ä¹ˆå¼ºï¼‰\n",
    "     - ROUGE ä¸ç®¡æµç•…åº¦ï¼Œæ‰€ä»¥åªé€‚åˆæ·±åº¦å­¦ä¹ çš„ç”Ÿæˆæ¨¡å‹ï¼šç»“æœéƒ½æ˜¯æµç•…çš„å‰æä¸‹ï¼ŒROUGE ååº”å‚ç…§å¥ä¸­å¤šå°‘å†…å®¹è¢«ç”Ÿæˆçš„å¥å­åŒ…å«ï¼ˆå¬å›ï¼‰\n",
    "5. **METEOR**: å¦ä¸€ä¸ªä»æœºå™¨ç¿»è¯‘é¢†åŸŸå€Ÿé‰´çš„æŒ‡æ ‡ã€‚ä¸ BLEU ç›¸æ¯”ï¼ŒMETEOR è€ƒè™‘äº†æ›´å¤šçš„å› ç´ ï¼Œå¦‚åŒä¹‰è¯åŒ¹é…ã€è¯å¹²åŒ¹é…ã€è¯åºç­‰ï¼Œå› æ­¤å®ƒé€šå¸¸è¢«è®¤ä¸ºæ˜¯ä¸€ä¸ªæ›´å…¨é¢çš„è¯„ä»·æŒ‡æ ‡ã€‚\n",
    "   - å¯¹è¯­è¨€å­¦å’Œè¯­ä¹‰è¯è¡¨æœ‰ä¾èµ–ï¼Œæ‰€ä»¥å¯¹è¯­è¨€ä¾èµ–å¼ºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735d93f",
   "metadata": {},
   "source": [
    "ä¸‹é¢ä»£ç ä½¿ç”¨NLTK(Natural Language Toolkit)å·¥å…·è®¡ç®—bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6155790-14c6-4931-b8c1-1c8de93538f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import re\n",
    "\n",
    "def bleu_score(output, expected_output):\n",
    "    def _tokenize(sentence):\n",
    "        # æ­£åˆ™è¡¨è¾¾å¼å®šä¹‰äº†è¦å»é™¤çš„æ ‡ç‚¹ç¬¦å·\n",
    "        return re.sub(r'[^\\w\\s]', '', sentence.lower()).split()\n",
    "    score = sentence_bleu(\n",
    "        [_tokenize(expected_output)], \n",
    "        _tokenize(output), \n",
    "        smoothing_function=SmoothingFunction().method3\n",
    "    )\n",
    "    print(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ef8d5-cc46-4350-8c9a-03ab54c08a26",
   "metadata": {},
   "source": [
    "### 1.4.4ã€è¿è¡Œæµ‹è¯•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee1c5a-f3ac-4024-89ab-3d54b877b845",
   "metadata": {},
   "source": [
    "Prompt æ¨¡æ¿ä¸ Chainï¼ˆLCELï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0c5623-af29-4c3a-b010-75f5b3e4ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import WikipediaRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Answer user's question according to the context below. \n",
    "Be brief, answer in no more than 20 words.\n",
    "CONTEXT_START\n",
    "{context}\n",
    "CONTEXT_END\n",
    "\n",
    "USER QUESTION:\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# å®šä¹‰è¯­è¨€æ¨¡å‹\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0)\n",
    "\n",
    "# å®šä¹‰Promptæ¨¡æ¿\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# æ£€ç´¢ wikipedia\n",
    "retriever = WikipediaRetriever(top_k_results=1)\n",
    "\n",
    "\n",
    "# å®šä¹‰è¾“å‡ºè§£æå™¨\n",
    "parser = StrOutputParser()\n",
    "\n",
    "wiki_qa_chain = (\n",
    "    {\n",
    "        \"context\": retriever, \n",
    "        \"input\": RunnablePassthrough()\n",
    "    } \n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3264acb-295c-4aa4-9ea4-9aca340bf52a",
   "metadata": {},
   "source": [
    "åœ¨æ•°æ®é›†ä¸Šæµ‹è¯•æ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10ab7b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010439917202667988\n",
      "0.019852949681089915\n",
      "0.008854366238409026\n",
      "0.027627972078128442\n",
      "0.03938557432578257\n",
      "0.06299033575335412\n",
      "0.10454786294785588\n",
      "0.034120260193708875\n",
      "0.030266181377145762\n",
      "0.01049627690924115\n",
      "0.046214670445444084\n",
      "0.027142536025659754\n",
      "0.023154722339652548\n",
      "0.09379548093903634\n",
      "0.13285541256864652\n",
      "0.015758838106836467\n",
      "0.029970944654446528\n",
      "0.09446965843281002\n",
      "0.05795599612995367\n",
      "0.02286956778061901\n"
     ]
    }
   ],
   "source": [
    "dataset = langfuse.get_dataset(\"wiki_qa\")\n",
    " \n",
    "for item in dataset.items:\n",
    "    # Langchain callback handler that automatically links the execution trace to the dataset item\n",
    "    handler = item.get_langchain_handler(run_name=\"test_wiki_qa-20\")\n",
    " \n",
    "    # Execute application and pass custom handler\n",
    "    output = wiki_qa_chain.invoke(item.input, config={\"callbacks\":[handler]})\n",
    "    \n",
    "    handler.trace.score(\n",
    "      name=\"bleu_score\",\n",
    "      value=bleu_score(output, item.expected_output)\n",
    "    )\n",
    " \n",
    "# Flush the langfuse client to ensure all data is sent to the server at the end of the experiment run\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0683e7f",
   "metadata": {},
   "source": [
    "<img src=\"lf_dataset_run.png\" width=1000px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5d874-95bb-4a81-8924-f97f00a6a6dc",
   "metadata": {},
   "source": [
    "### 1.5ã€Prompt ç‰ˆæœ¬ç®¡ç†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd11a845-f9e2-4110-9223-53ffc428b280",
   "metadata": {},
   "source": [
    "[ä½¿ç”¨æ–‡æ¡£](https://langfuse.com/docs/prompts/get-started)\n",
    "\n",
    "<img src=\"prompt_management.png\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fece2096-b931-45cb-9754-28b3969b8cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ä¸‹é¢æ˜¯æœ€æ–°productionç‰ˆæœ¬==============\n",
      "*********\n",
      "ä½ æ˜¯AIGCè¯¾ç¨‹çš„åŠ©æ•™ï¼Œä½ çš„å·¥ä½œæ˜¯ä»å­¦å‘˜çš„è¯¾å ‚äº¤æµä¸­é€‰æ‹©å‡ºéœ€è¦è€å¸ˆå›ç­”çš„é—®é¢˜ï¼ŒåŠ ä»¥æ•´ç†ä»¥äº¤ç»™è€å¸ˆå›ç­”ã€‚\n",
      "\n",
      "ä½ çš„é€‰æ‹©éœ€è¦éµå¾ªä»¥ä¸‹åŸåˆ™ï¼š\n",
      "1 éœ€è¦è€å¸ˆå›ç­”çš„é—®é¢˜æ˜¯æŒ‡ä¸è¯¾ç¨‹å†…å®¹æˆ–AI/LLMç›¸å…³çš„æŠ€æœ¯é—®é¢˜ï¼›\n",
      "2 è¯„è®ºæ€§çš„è§‚ç‚¹ã€é—²èŠã€è¡¨è¾¾æ¨¡ç³Šä¸æ¸…çš„å¥å­ï¼Œä¸éœ€è¦è€å¸ˆå›ç­”ï¼›\n",
      "3 å­¦ç”Ÿè¾“å…¥ä¸æ„æˆç–‘é—®å¥çš„ï¼Œä¸éœ€è¦è€å¸ˆå›ç­”ï¼›\n",
      "4 å­¦ç”Ÿé—®é¢˜ä¸­å¦‚æœç”¨â€œè¿™â€ã€â€œé‚£â€ç­‰ä»£è¯æŒ‡ä»£ï¼Œä¸ç®—è¡¨è¾¾æ¨¡ç³Šä¸æ¸…ï¼Œè¯·æ ¹æ®é—®é¢˜å†…å®¹åˆ¤æ–­æ˜¯å¦éœ€è¦è€å¸ˆå›ç­”ã€‚\n",
      " \n",
      "è¯¾ç¨‹å†…å®¹:\n",
      "test\n",
      "*********\n",
      "å­¦å‘˜è¾“å…¥:\n",
      "è¿™æ˜¯æˆ‘çš„è¾“å…¥\n",
      "*********\n",
      "Analyse the student's input according to the lecture's contents and your criteria.\n",
      "Output your analysis process step by step.\n",
      "Finally, output a single letter Y or N in a separate line.\n",
      "Y means that the input needs to be answered by the teacher.\n",
      "N means that the input does not needs to be answered by the teacher.\n",
      "============ä¸‹é¢è·å–æŒ‡å®šç‰ˆæœ¬ç‰ˆæœ¬==============\n",
      "*********\n",
      "ä½ æ˜¯AIGCè¯¾ç¨‹çš„åŠ©æ•™ï¼Œä½ çš„å·¥ä½œæ˜¯ä»å­¦å‘˜çš„è¯¾å ‚äº¤æµä¸­é€‰æ‹©å‡ºéœ€è¦è€å¸ˆå›ç­”çš„é—®é¢˜ï¼ŒåŠ ä»¥æ•´ç†ä»¥äº¤ç»™è€å¸ˆå›ç­”ã€‚\n",
      " \n",
      "è¯¾ç¨‹å†…å®¹:\n",
      "test\n",
      "*********\n",
      "å­¦å‘˜è¾“å…¥:\n",
      "è¿™æ˜¯æˆ‘çš„è¾“å…¥\n",
      "*********\n",
      "å¦‚æœè¿™æ˜¯ä¸€ä¸ªéœ€è¦è€å¸ˆç­”ç–‘çš„é—®é¢˜ï¼Œå›å¤Yï¼Œå¦åˆ™å›å¤Nã€‚\n",
      "åªå›å¤Yæˆ–Nï¼Œä¸è¦å›å¤å…¶ä»–å†…å®¹ã€‚\"\"\")\n"
     ]
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "from langchain_core.prompts import PromptTemplate\n",
    " \n",
    "\n",
    "langfuse = Langfuse()\n",
    " \n",
    "print(\"============ä¸‹é¢æ˜¯æœ€æ–°productionç‰ˆæœ¬==============\")\n",
    "langfuse_prompt = langfuse.get_prompt(\"need_answer\")\n",
    " \n",
    "langchain_prompt = PromptTemplate.from_template(langfuse_prompt.get_langchain_prompt())\n",
    "print(langchain_prompt.format(outlines=\"test\", user_input=\"è¿™æ˜¯æˆ‘çš„è¾“å…¥\"))\n",
    "\n",
    "\n",
    "print(\"============ä¸‹é¢è·å–æŒ‡å®šç‰ˆæœ¬ç‰ˆæœ¬==============\")\n",
    "langfuse_prompt = langfuse.get_prompt(\"need_answer\", version=1)\n",
    " \n",
    "langchain_prompt = PromptTemplate.from_template(langfuse_prompt.get_langchain_prompt())\n",
    "print(langchain_prompt.format(outlines=\"test\", user_input=\"è¿™æ˜¯æˆ‘çš„è¾“å…¥\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f2552-f3af-4484-91e3-3c2308c05921",
   "metadata": {},
   "source": [
    "## 2ã€LangSmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f950af-34cd-43f1-a1a2-ed18d3743f1f",
   "metadata": {},
   "source": [
    "å¹³å°å…¥å£ï¼šhttps://www.langchain.com/langsmith\n",
    "\n",
    "æ–‡æ¡£åœ°å€ï¼šhttps://python.langchain.com/docs/langsmith/walkthrough\n",
    "\n",
    "å°†ä½ çš„ LangChain åº”ç”¨ä¸ LangSmith é“¾æ¥ï¼Œéœ€è¦ï¼š\n",
    "\n",
    "1. æ³¨å†Œè´¦å·ï¼Œå¹¶ç”³è¯·ä¸€ä¸ª`LANGCHAIN_API_KEY`\n",
    "2. åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®ä»¥ä¸‹å€¼\n",
    "\n",
    "```\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_PROJECT=YOUR_PROJECT_NAME #è‡ªå®šä¹‰é¡¹ç›®åç§°\n",
    "LANGCHAIN_ENDPOINT=https://api.smith.langchain.com #LangSmithçš„æœåŠ¡ç«¯ç‚¹\n",
    "LANGCHAIN_API_KEY=LANGCHAIN_API_KEY # LangChain API Key\n",
    "```\n",
    "3. ç¨‹åºä¸­çš„è°ƒç”¨å°†è‡ªåŠ¨è¢«è®°å½•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dddaf145-15f2-450e-903c-2de85d6aeb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello AGIClass! How can I assist you today?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# å®šä¹‰è¯­è¨€æ¨¡å‹\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# å®šä¹‰Promptæ¨¡æ¿\n",
    "prompt = PromptTemplate.from_template(\"Say hello to {input}!\")\n",
    "\n",
    "# å®šä¹‰è¾“å‡ºè§£æå™¨\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"input\":RunnablePassthrough()} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke(\"AGIClass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59edfa6-2282-48ee-9c97-7af6a2532ddf",
   "metadata": {},
   "source": [
    "<img src=\"langsmith-example.png\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c59c7c0-9e49-4230-841c-900487b716cb",
   "metadata": {},
   "source": [
    "### 2.2ã€æ•°æ®é›†ç®¡ç†ä¸æµ‹è¯•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e0dd2-7ea4-4799-9fc6-4b786a8302d3",
   "metadata": {},
   "source": [
    "### 2.2.1ã€åœ¨çº¿æ ‡æ³¨æ¼”ç¤º\n",
    "1ã€åˆ›å»ºæ•°æ®é›†\n",
    "\n",
    "<img src=\"ls_create_dataset.png\" width=\"1000px\">\n",
    "\n",
    "2ã€æ·»åŠ åˆ°æ•°æ®é›†\n",
    "<img src=\"ls_add_to_dataset.png\" width=\"1000px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b4a82-8f91-480e-8e7c-0f7941314c7c",
   "metadata": {},
   "source": [
    "### 2.2.2ã€ä¸Šä¼ æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e978a2d-74cd-4b9c-a3cb-18f81b091c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "import json\n",
    "\n",
    "\n",
    "data = []\n",
    "with open('example_dataset.jsonl','r',encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        example = json.loads(line.strip())\n",
    "        data.append(example)\n",
    "        \n",
    "        client = Client()\n",
    "\n",
    "# åˆ›å»ºæ•°æ®é›†\n",
    "dataset_name = \"wiki-qa\"\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name, #æ•°æ®é›†åç§°\n",
    "    description=\"wikié—®ç­”æ•°æ®é›†\", #æ•°æ®é›†æè¿°\n",
    ")\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"input\":item[\"question\"]} for item in data[:20]], \n",
    "    outputs=[{\"output\":item[\"answer\"]} for item in data[:20]], \n",
    "    dataset_id=dataset.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb080d2",
   "metadata": {},
   "source": [
    "<img src=\"ls_upload_data.png\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f473e5-3873-42d0-b900-f0d9cea94412",
   "metadata": {},
   "source": [
    "### 2.2.3ã€è¯„ä¼°å‡½æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1d803-5b09-4756-89a1-8377c22300e5",
   "metadata": {},
   "source": [
    "LanChainå†…ç½®3ç§è¯„ä¼°å™¨ï¼š\n",
    "\n",
    "ï¼ˆ1ï¼‰String Evaluators: é€šè¿‡å°†ç”Ÿæˆçš„è¾“å‡ºï¼ˆé¢„æµ‹ï¼‰ä¸å‚è€ƒå­—ç¬¦ä¸²æˆ–è¾“å…¥è¿›è¡Œæ¯”è¾ƒæ¥è¯„ä¼°è¯­è¨€æ¨¡å‹çš„æ€§èƒ½ã€‚https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/string/\n",
    "\n",
    "EnvaluatorType: https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html\n",
    "\n",
    "ï¼ˆ2ï¼‰Trajectory Evaluatorsï¼šç”¨äºè¯„ä¼°agentçš„è¡Œä¸ºè¡¨ç°ã€‚https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/trajectory/\n",
    "\n",
    "\n",
    "ï¼ˆ3ï¼‰Comparison Evaluatorsï¼šç”¨äºè¯„ä¼°ä¸åŒæ¨¡å‹çš„è¾“å‡ºç»“æœï¼Œå¸¸ç”¨äºä¸¤ä¸ªè¯­è¨€æ¨¡å‹ä¹‹é—´çš„A/Bæµ‹è¯•ï¼Œæˆ–è€…æ¯”è¾ƒåŒä¸€æ¨¡å‹çš„ä¸åŒç‰ˆæœ¬ã€‚https://python.langchain.com/v0.1/docs/guides/productionization/evaluation/comparison/\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84838882",
   "metadata": {},
   "source": [
    "ä¸‹é¢çš„ä»£ç æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰çš„StringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5616ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import StringEvaluator\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import re\n",
    "from typing import Optional, Any\n",
    "\n",
    "class BleuEvaluator(StringEvaluator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def requires_input(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def requires_reference(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def evaluation_name(self) -> str:\n",
    "        return \"bleu_score\"\n",
    "\n",
    "    def _tokenize(self,sentence):\n",
    "        # æ­£åˆ™è¡¨è¾¾å¼å®šä¹‰äº†è¦å»é™¤çš„æ ‡ç‚¹ç¬¦å·\n",
    "        return re.sub(r'[^\\w\\s]', '', sentence.lower()).split()\n",
    "    \n",
    "    def _evaluate_strings(\n",
    "        self,\n",
    "        prediction: str,\n",
    "        input: Optional[str] = None,\n",
    "        reference: Optional[str] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> dict:\n",
    "        bleu_score = sentence_bleu(\n",
    "            [self._tokenize(reference)], \n",
    "            self._tokenize(prediction), \n",
    "            smoothing_function=SmoothingFunction().method3\n",
    "        )\n",
    "        return {\"score\": bleu_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3813b43c-7ecd-46e3-9a2c-9b880bfea413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import EvaluatorType\n",
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    # è¯„ä¼°å™¨ï¼Œå¯å¤šé€‰\n",
    "    evaluators=[\n",
    "        # ä½¿ç”¨ä¸€ä¸ªå†…ç½®çš„StringEvaluator\n",
    "        EvaluatorType.QA,\n",
    "    ],\n",
    "    # å¯è¿½åŠ è‡ªå®šè¯„ä¼°æ ‡å‡†\n",
    "    custom_evaluators=[BleuEvaluator()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef2db5-39d8-4e0a-aa1c-4235944acd93",
   "metadata": {},
   "source": [
    "### 2.2.4ã€è¿è¡Œæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1e4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c56d52ec-d58a-4720-a9a4-1b8f8130d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import WikipediaRetriever\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "Answer user's question according to the context below. \n",
    "Be brief, answer in no more than 20 words.\n",
    "CONTEXT_START\n",
    "{context}\n",
    "CONTEXT_END\n",
    "\n",
    "USER QUESTION:\n",
    "{input}\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# æ£€ç´¢ wikipedia\n",
    "retriever = WikipediaRetriever(top_k_results=1)\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain_v1 = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"input\") | retriever | (lambda docs: \"\\n\".join([doc.page_content for doc in docs])),\n",
    "        \"input\":  itemgetter(\"input\")\n",
    "     }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b92f2e89-0bc6-41df-b5b4-7fa938639795",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'LangChain_WikiQA_Project-d79243cd' at:\n",
      "https://smith.langchain.com/o/101a6386-9727-5197-958a-5868b750060a/datasets/404233ce-938e-4648-b8d2-3d21c394c3b6/compare?selectedSessions=8a664c71-cf73-4be2-b3dc-7d1018334f0e\n",
      "\n",
      "View all tests for Dataset wiki-qa at:\n",
      "https://smith.langchain.com/o/101a6386-9727-5197-958a-5868b750060a/datasets/404233ce-938e-4648-b8d2-3d21c394c3b6\n",
      "[------------------------------------------------->] 20/20"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.bleu_score</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19fcca60-b329-4157-b258-4a3041b5e4cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.049011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.188564</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.054358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.064550</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.599712</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.019579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.757824</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.030168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.573589</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.062321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.923407</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.250270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.917378</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.bleu_score error  execution_time  \\\n",
       "count             20.000000     0       20.000000   \n",
       "unique                  NaN     0             NaN   \n",
       "top                     NaN   NaN             NaN   \n",
       "freq                    NaN   NaN             NaN   \n",
       "mean               0.049011   NaN       10.188564   \n",
       "std                0.054358   NaN        2.064550   \n",
       "min                0.010058   NaN        7.599712   \n",
       "25%                0.019579   NaN        8.757824   \n",
       "50%                0.030168   NaN        9.573589   \n",
       "75%                0.062321   NaN       11.923407   \n",
       "max                0.250270   NaN       14.917378   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     20  \n",
       "unique                                    20  \n",
       "top     19fcca60-b329-4157-b258-4a3041b5e4cf  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.smith import arun_on_dataset, run_on_dataset\n",
    "\n",
    "from uuid import uuid4\n",
    "\n",
    "unique_id = uuid4().hex[0:8]\n",
    "\n",
    "results = await arun_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=chain_v1,\n",
    "    evaluation=evaluation_config,\n",
    "    verbose=True,\n",
    "    client=client,\n",
    "    project_name=f\"LangChain_WikiQA_Project-{unique_id}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8cc751",
   "metadata": {},
   "source": [
    "<img src=\"ls_dataset_run.png\" width=\"1000px\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
